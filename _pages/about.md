


## Contents

- [Introduction](#iclr-2024-blogposts-track)
- [Challenge Description](#spotlight)
- [Dataset details](#accepted-posts)
- [Key Dates](#key-dates)
- [Submissions](#submissions)
- [Organizers](#organizers)

# Introduction

The field of Document Analysis and Recognition (DAR) has made remarkable strides in recent years, driven by the integration of Natural Language Processing (NLP) and Computer Vision (CV) techniques. These advancements have enabled holistic Document Understanding (DU) for Visually Rich Documents (VRDs), which require the seamless fusion of textual, visual, and layout information. Despite these achievements, the domain of handwritten document understanding remains a persistent challenge, especially for complex layouts and diverse content types.

To increase research in this field, we present this ICDAR Handwritten Notes Understanding competition, in which the model needs to answer the framed questions that span over 2000 handwritten note samples—composed of multipage handwritten exam notes from competitive exams in India, such as IIT-JEE, GATE, and various science disciplines. Spanning subjects like computer science, mathematics, physics, chemistry, and engineering. 

This competition will also present new performance measuring benchmarks like NDCG@5, Recall@K, and MRR alongside standard ANLS and Accuracy to assess transcription precision, ranking, and relevance. By bridging layout analysis, HTR, and question answering, this challenge aims to advance state-of-the-art methodologies in document AI, fostering innovation in handling complex, context-sensitive retrieval tasks. Furthermore, it aligns with the goals of ICDAR by promoting research that tackles real-world complexities, such as low-resource settings, multi-topic domains, and multipage reasoning.

Overall, this competition will catalyze practical applications in the handwritten domain, such as automated evaluation of handwritten exam responses and bridging academic and industrial needs. We aim to set a new standard for understanding handwritten documents and drive impactful advancements in the DAR landscape by fostering community engagement through robust benchmarks and reproducible platforms.

## Competition Details

In our competition the dataset will be given the question answers. The question answers span over 2000 Handwritten notes from different scientific fields like mathematics, physics, chemistry, computer science and engineering. The task is divide into two parts. One is Evidence based grounding and another one is open domain VQA on a collection of Handwritten Notes.

**Evidence-Based Grounding in Handwritten VQA**: This task involves developing a system to answer questions based on 3–4 pages of handwritten documents. It requires interpreting handwriting, understanding context, and providing evidence-based answers, ranging from specific extractions to contextually generated responses.

**Open-Domain VQA on a Collection of Handwritten Notes**: In this task, the focus shifts to an open-domain setting within the science domain, where the system must handle a vast collection of handwritten notes on various scientific subjects. The process involves retrieving relevant handwritten pages and using a generative model to interpret the content and produce accurate, query-based answers.


**Examples are coming soon**



## Competition Updates

**Registration Opens**: 5th January, 2025

**Registration Close**: 31st March, 2025

**Test Data Release**: 1st April, 2025

**Results Submission Deadline**: 15th April, 2025

**Winner Announcement**: 30th April, 2025



## Contact

For any query contact aniket.pal@research.iiit.ac.in, sbiswas@cvc.uab.cat

## Organizers

**Dr. Aniket Pal**, Postdoctoral researcher, CVIT Lab, IIIT Hydearabad, India

**Sanket Biswas**, PHD fellow, Computer Vision Center, Universitat Autònoma de Barcelona, Spain

**Dr. Ajoy Mondal**, Postdoctoral researcher, CVIT Lab, IIIT Hydearabad, India

**Prof. Dimosthenis Karatzas**, Professor, Computer Vision Center, Universitat Autònoma de Barcelona, Spain

**Prof. Josep Lladós**, Professor, Computer Vision Center, Universitat Autònoma de Barcelona, Spain

**Prof. C.V. Jawahar**, Professor, CVIT Lab, IIIT Hydearabad


## References

<a name="Litt">Jimeno Yepes, Antonio and Zhong, Peter and Burdick, Douglas. ICDAR 2021 competition on scientific literature parsing.</a>

<a name="Litt">Mondal, Ajoy and Mahadevan, Vijay and Manmatha, R and Jawahar, CV. ICDAR 2024 Competition on Recognition and VQA on Handwritten Documents </a>


